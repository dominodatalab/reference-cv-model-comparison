{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4459ea2-2742-4cad-87c5-a9b9f5cfd684",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import urllib.request\n",
    "import utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36964526-ba0c-4b48-8765-8edb146d3a61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'AzureExecutionProvider', 'CPUExecutionProvider']\n"
     ]
    }
   ],
   "source": [
    "import os, onnxruntime as ort\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # or unset it: os.environ.pop(\"CUDA_VISIBLE_DEVICES\", None)\n",
    "\n",
    "# Must be the GPU build:\n",
    "# pip install --upgrade onnxruntime-gpu==1.18.0   # pick version matching your CUDA 12.x stack\n",
    "\n",
    "prov = ort.get_available_providers()\n",
    "print(prov)\n",
    "assert \"CUDAExecutionProvider\" in prov, f\"ORT not GPU-enabled. Providers={prov}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20d38dd6-3f28-460c-b010-c38e13305fb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasets_dir = os.environ['DOMINO_DATASETS_DIR']\n",
    "project_ds_folder = os.environ['DOMINO_PROJECT_NAME'] \n",
    "\n",
    "download_base_folder=f\"{datasets_dir}/{project_ds_folder}\"\n",
    "models_folder = \"models\"\n",
    "yolo_model_name=\"yolov8n\"\n",
    "model_names = [\"yolov8n.pt\", \"yolov5n.pt\", \"yolov8m.pt\", \"yolov8s.pt\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4aae6ad0-baf5-4f36-afc9-d09248480575",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Adds: log entire Ultralytics run dir to MLflow, then delete it.\n",
    "# Writes the run under /tmp/ultra_runs/<name>, logs it, removes it.\n",
    "\n",
    "import os, time, yaml, math, random, json, shutil, statistics as stats\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, List\n",
    "from datetime import datetime\n",
    "import mlflow\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "from ultralytics import YOLO\n",
    "\n",
    "try:\n",
    "    import mlflow\n",
    "    _HAS_MLFLOW = True\n",
    "except Exception:\n",
    "    _HAS_MLFLOW = False\n",
    "\n",
    "\n",
    "def _ensure_dir(p: Path) -> Path:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "    return p\n",
    "\n",
    "\n",
    "def _latency_benchmark(model: YOLO, image_paths: List[Path], imgsz: int, device: str) -> Dict[str, Any]:\n",
    "    if not image_paths:\n",
    "        return {\"p50_ms\": None, \"p90_ms\": None, \"p99_ms\": None, \"mean_ms\": None, \"count\": 0}\n",
    "    lat_ms = []\n",
    "    _ = model.predict(source=str(image_paths[0]), imgsz=imgsz, device=device, verbose=False)  # warmup\n",
    "    for p in image_paths:\n",
    "        t0 = time.perf_counter()\n",
    "        _ = model.predict(source=str(p), imgsz=imgsz, device=device, verbose=False)\n",
    "        lat_ms.append((time.perf_counter() - t0) * 1000.0)\n",
    "    lat_sorted = sorted(lat_ms)\n",
    "    def pct(v, q):\n",
    "        idx = min(len(v)-1, max(0, int(math.ceil(q*len(v))-1)))\n",
    "        return v[idx]\n",
    "    return {\n",
    "        \"p50_ms\": pct(lat_sorted, 0.50),\n",
    "        \"p90_ms\": pct(lat_sorted, 0.90),\n",
    "        \"p99_ms\": pct(lat_sorted, 0.99),\n",
    "        \"mean_ms\": float(stats.mean(lat_sorted)),\n",
    "        \"count\": len(lat_sorted),\n",
    "        \"raw_ms\": lat_ms,\n",
    "    }\n",
    "\n",
    "\n",
    "def ensure_mlflow_experiment(experiment_name: str) -> int:\n",
    "    \"\"\"\n",
    "    Ensure an MLflow experiment with the given name exists.\n",
    "    If it does not, create it. Then set it as the current experiment.\n",
    "\n",
    "    Args:\n",
    "        experiment_name: Name of the experiment\n",
    "        artifact_location: Optional path or URI where artifacts will be stored\n",
    "\n",
    "    Returns:\n",
    "        experiment_id (int)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        exp = mlflow.get_experiment_by_name(experiment_name)\n",
    "        if exp is None:\n",
    "            exp_id = mlflow.create_experiment(\n",
    "                experiment_name\n",
    "            )\n",
    "        else:\n",
    "            exp_id = exp.experiment_id\n",
    "        mlflow.set_experiment(experiment_name)\n",
    "        return exp_id\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to ensure experiment {experiment_name}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "# assumes this helper exists as defined earlier\n",
    "# def load_registered_yolo_model(model_name: str, version: str = \"latest\") -> YOLO: ...\n",
    "\n",
    "def evaluate_model(\n",
    "    base_path: str,\n",
    "    model_path: str = None,\n",
    "    imgsz: int = 640,\n",
    "    device: str = \"cpu\",\n",
    "    limit_images: int = 1000,\n",
    "    subset_seed: int = 0,\n",
    "    experiment_name: str = None,\n",
    "    registry_model_name: str = None,\n",
    "    registry_model_version: str = \"latest\",\n",
    "    parent_run_id: str = None,  # NEW\n",
    ") -> Dict[str, Any]:\n",
    "    base = Path(base_path)\n",
    "    img_dir = base / \"images\" / \"val2017\"\n",
    "    if not img_dir.exists():\n",
    "        raise FileNotFoundError(f\"Missing image dir: {img_dir}\")\n",
    "\n",
    "    def _ensure_dir(p: Path) -> Path:\n",
    "        p.mkdir(parents=True, exist_ok=True)\n",
    "        return p\n",
    "\n",
    "    artifacts = _ensure_dir(base / \"artifacts\")\n",
    "    plots_dir = _ensure_dir(artifacts / \"plots\")\n",
    "    metrics_dir = _ensure_dir(artifacts / \"metrics\")\n",
    "    config_dir = _ensure_dir(artifacts / \"config\")\n",
    "\n",
    "    all_imgs = sorted([p for p in img_dir.glob(\"*.jpg\")] +\n",
    "                      [p for p in img_dir.glob(\"*.jpeg\")] +\n",
    "                      [p for p in img_dir.glob(\"*.png\")])\n",
    "    if not all_imgs:\n",
    "        raise RuntimeError(f\"No images found under {img_dir}\")\n",
    "    rng = random.Random(subset_seed)\n",
    "    rng.shuffle(all_imgs)\n",
    "    sub_imgs = all_imgs[:min(limit_images, len(all_imgs))]\n",
    "\n",
    "    subset_list = artifacts / \"val_subset.txt\"\n",
    "    with open(subset_list, \"w\") as f:\n",
    "        for p in sub_imgs:\n",
    "            f.write(str(p.resolve()) + \"\\n\")\n",
    "\n",
    "    data_config = {\n",
    "        \"path\": str(base),\n",
    "        \"train\": \"images/val2017\",\n",
    "        \"val\": str(subset_list),\n",
    "        \"names\": list(range(80)),\n",
    "    }\n",
    "    yaml_path = base / \"coco_val_subset.yaml\"\n",
    "    with open(yaml_path, \"w\") as f:\n",
    "        yaml.dump(data_config, f)\n",
    "\n",
    "    if registry_model_name:\n",
    "        model = utilities.load_registered_yolo_model(registry_model_name, version=registry_model_version)\n",
    "        model_id = f\"{registry_model_name}:{registry_model_version}\"\n",
    "    else:\n",
    "        if not model_path:\n",
    "            raise ValueError(\"Provide either registry_model_name or model_path\")\n",
    "        model = YOLO(model_path, task=\"detect\")\n",
    "        model_id = Path(model_path).stem\n",
    "\n",
    "    tmp_project = Path(\"/tmp/ultra_runs\")\n",
    "    run_name = f\"val_{model_id}_subset{len(sub_imgs)}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "\n",
    "    val_res = model.val(\n",
    "        data=str(yaml_path),\n",
    "        imgsz=imgsz,\n",
    "        device=device,\n",
    "        save_json=False,\n",
    "        verbose=False,\n",
    "        project=str(tmp_project),\n",
    "        name=run_name,\n",
    "        exist_ok=True,\n",
    "        workers=0,\n",
    "    )\n",
    "    save_dir = Path(val_res.save_dir)\n",
    "\n",
    "    metrics = {\n",
    "        \"map\": float(val_res.box.map),\n",
    "        \"ap50\": float(val_res.box.map50),\n",
    "        \"ap75\": float(val_res.box.map75),\n",
    "        \"mean_precision\": float(val_res.box.mp),\n",
    "        \"mean_recall\": float(val_res.box.mr),\n",
    "        \"evaluated_images\": len(sub_imgs),\n",
    "        \"model_id\": model_id,\n",
    "    }\n",
    "    (metrics_dir / \"headline.json\").write_text(json.dumps(metrics, indent=2))\n",
    "\n",
    "    try:\n",
    "        latency = _latency_benchmark(model, sub_imgs[:min(100, len(sub_imgs))], imgsz=imgsz, device=device)\n",
    "    except NameError:\n",
    "        latency = {}\n",
    "    (metrics_dir / \"latency.json\").write_text(json.dumps({k: v for k, v in latency.items() if k != \"raw_ms\"}, indent=2))\n",
    "\n",
    "    if latency.get(\"raw_ms\"):\n",
    "        plt.figure()\n",
    "        plt.hist(latency[\"raw_ms\"], bins=20)\n",
    "        plt.xlabel(\"Latency (ms)\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.title(\"Per-image latency (batch=1)\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(plots_dir / \"latency_hist.png\")\n",
    "        plt.close()\n",
    "\n",
    "    eval_cfg = {\n",
    "        \"imgsz\": imgsz,\n",
    "        \"device\": device,\n",
    "        \"subset_seed\": subset_seed,\n",
    "        \"limit_images\": limit_images,\n",
    "        \"subset_list\": str(subset_list),\n",
    "        \"model_id\": model_id,\n",
    "        \"ultralytics_save_dir\": str(save_dir),\n",
    "        \"source\": \"registry\" if registry_model_name else \"path\",\n",
    "    }\n",
    "    (config_dir / \"eval.json\").write_text(json.dumps(eval_cfg, indent=2))\n",
    "    \n",
    "    if experiment_name:\n",
    "        utilities.ensure_mlflow_experiment(experiment_name)\n",
    "\n",
    "    if experiment_name or parent_run_id:\n",
    "        try:\n",
    "            if parent_run_id:\n",
    "                #with mlflow.start_run(run_name=run_name,run_id=parent_run_id):\n",
    "                    with mlflow.start_run(run_name=run_name, nested=True):\n",
    "                        mlflow.set_tags({\"model_id\": model_id, \"source\": eval_cfg[\"source\"]})\n",
    "                        mlflow.log_params({\n",
    "                            \"imgsz\": imgsz, \"device\": device,\n",
    "                            \"limit_images\": len(sub_imgs), \"subset_seed\": subset_seed\n",
    "                        })\n",
    "                        mlflow.log_metrics({\n",
    "                            \"map\": metrics[\"map\"], \"ap50\": metrics[\"ap50\"], \"ap75\": metrics[\"ap75\"],\n",
    "                            \"mean_precision\": metrics[\"mean_precision\"], \"mean_recall\": metrics[\"mean_recall\"],\n",
    "                            \"latency_p50_ms\": latency.get(\"p50_ms\") or 0.0,\n",
    "                            \"latency_p90_ms\": latency.get(\"p90_ms\") or 0.0,\n",
    "                            \"latency_p99_ms\": latency.get(\"p99_ms\") or 0.0,\n",
    "                            \"latency_mean_ms\": latency.get(\"mean_ms\") or 0.0,\n",
    "                        })\n",
    "                        mlflow.log_artifact(str(metrics_dir / \"headline.json\"))\n",
    "                        mlflow.log_artifact(str(metrics_dir / \"latency.json\"))\n",
    "                        mlflow.log_artifact(str(config_dir / \"eval.json\"))\n",
    "                        mlflow.log_artifact(str(artifacts / \"val_subset.txt\"))\n",
    "                        if (plots_dir / \"latency_hist.png\").exists():\n",
    "                            mlflow.log_artifact(str(plots_dir / \"latency_hist.png\"))\n",
    "                        if save_dir.exists():\n",
    "                            mlflow.log_artifacts(str(save_dir), artifact_path=\"ultralytics_run\")\n",
    "            else:\n",
    "                with mlflow.start_run(run_name=run_name):\n",
    "                    mlflow.set_tags({\"model_id\": model_id, \"source\": eval_cfg[\"source\"]})\n",
    "                    mlflow.log_params({\n",
    "                        \"imgsz\": imgsz, \"device\": device,\n",
    "                        \"limit_images\": len(sub_imgs), \"subset_seed\": subset_seed\n",
    "                    })\n",
    "                    mlflow.log_metrics({\n",
    "                        \"map\": metrics[\"map\"], \"ap50\": metrics[\"ap50\"], \"ap75\": metrics[\"ap75\"],\n",
    "                        \"mean_precision\": metrics[\"mean_precision\"], \"mean_recall\": metrics[\"mean_recall\"],\n",
    "                        \"latency_p50_ms\": latency.get(\"p50_ms\") or 0.0,\n",
    "                        \"latency_p90_ms\": latency.get(\"p90_ms\") or 0.0,\n",
    "                        \"latency_p99_ms\": latency.get(\"p99_ms\") or 0.0,\n",
    "                        \"latency_mean_ms\": latency.get(\"mean_ms\") or 0.0,\n",
    "                    })\n",
    "                    mlflow.log_artifact(str(metrics_dir / \"headline.json\"))\n",
    "                    mlflow.log_artifact(str(metrics_dir / \"latency.json\"))\n",
    "                    mlflow.log_artifact(str(config_dir / \"eval.json\"))\n",
    "                    mlflow.log_artifact(str(artifacts / \"val_subset.txt\"))\n",
    "                    if (plots_dir / \"latency_hist.png\").exists():\n",
    "                        mlflow.log_artifact(str(plots_dir / \"latency_hist.png\"))\n",
    "                    if save_dir.exists():\n",
    "                        mlflow.log_artifacts(str(save_dir), artifact_path=\"ultralytics_run\")\n",
    "        finally:\n",
    "            if save_dir.exists():\n",
    "                shutil.rmtree(save_dir, ignore_errors=True)\n",
    "            parent = tmp_project\n",
    "            if parent.exists() and not any(parent.iterdir()):\n",
    "                shutil.rmtree(parent, ignore_errors=True)\n",
    "    else:\n",
    "        if save_dir.exists():\n",
    "            shutil.rmtree(save_dir, ignore_errors=True)\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03455c5b-60c5-4afa-b281-ef37e790fed8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating yolov8n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading artifacts: 100%|██████████| 6/6 [00:01<00:00,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Loaded] yolov8n:latest from /tmp/yolov8n__hou17ow/model.onnx\n",
      "Ultralytics 8.3.182 🚀 Python-3.8.10 torch-2.3.1+cu121 CUDA:0 (NVIDIA A10G, 22724MiB)\n",
      "Loading /tmp/yolov8n__hou17ow/model.onnx for ONNX Runtime inference...\n",
      "Using ONNX Runtime CUDAExecutionProvider\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting batch=1 input of shape (1, 3, 640, 640)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 3.7±0.1 ms, read: 108.3±38.1 MB/s, size: 167.0 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/data/reference-cv-model-comparison/coco/labels/val2017.cache... 50 images, 2 backgrounds, 0 corrupt: 100%|██████████| 50/50 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 50/50 [00:01<00:00, 36.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         50        564      0.529      0.531      0.585      0.446\n",
      "Speed: 0.9ms preprocess, 3.8ms inference, 0.0ms loss, 12.2ms postprocess per image\n",
      "Results saved to \u001b[1m/tmp/ultra_runs/val_yolov8n:latest_subset50_20250821_132507\u001b[0m\n",
      "Loading /tmp/yolov8n__hou17ow/model.onnx for ONNX Runtime inference...\n",
      "Using ONNX Runtime CUDAExecutionProvider\n",
      "Evaluating yolov5n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 6/6 [00:01<00:00,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Loaded] yolov5n:latest from /tmp/yolov5n_puhqva4m/model.onnx\n",
      "Ultralytics 8.3.182 🚀 Python-3.8.10 torch-2.3.1+cu121 CUDA:0 (NVIDIA A10G, 22724MiB)\n",
      "Loading /tmp/yolov5n_puhqva4m/model.onnx for ONNX Runtime inference...\n",
      "Using ONNX Runtime CUDAExecutionProvider\n",
      "Setting batch=1 input of shape (1, 3, 640, 640)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 127.7±32.1 MB/s, size: 187.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/data/reference-cv-model-comparison/coco/labels/val2017.cache... 50 images, 2 backgrounds, 0 corrupt: 100%|██████████| 50/50 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 50/50 [00:00<00:00, 67.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         50        564       0.59      0.521       0.56      0.419\n",
      "Speed: 0.3ms preprocess, 4.0ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Results saved to \u001b[1m/tmp/ultra_runs/val_yolov5n:latest_subset50_20250821_132523\u001b[0m\n",
      "Loading /tmp/yolov5n_puhqva4m/model.onnx for ONNX Runtime inference...\n",
      "Using ONNX Runtime CUDAExecutionProvider\n",
      "Evaluating yolov8m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 6/6 [00:08<00:00,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Loaded] yolov8m:latest from /tmp/yolov8m_diqozcwp/model.onnx\n",
      "Ultralytics 8.3.182 🚀 Python-3.8.10 torch-2.3.1+cu121 CUDA:0 (NVIDIA A10G, 22724MiB)\n",
      "Loading /tmp/yolov8m_diqozcwp/model.onnx for ONNX Runtime inference...\n",
      "Using ONNX Runtime CUDAExecutionProvider\n",
      "Setting batch=1 input of shape (1, 3, 640, 640)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 91.8±39.5 MB/s, size: 156.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/data/reference-cv-model-comparison/coco/labels/val2017.cache... 50 images, 2 backgrounds, 0 corrupt: 100%|██████████| 50/50 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 50/50 [00:00<00:00, 50.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         50        564      0.635      0.675      0.687      0.547\n",
      "Speed: 0.4ms preprocess, 9.0ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Results saved to \u001b[1m/tmp/ultra_runs/val_yolov8m:latest_subset50_20250821_132542\u001b[0m\n",
      "Loading /tmp/yolov8m_diqozcwp/model.onnx for ONNX Runtime inference...\n",
      "Using ONNX Runtime CUDAExecutionProvider\n",
      "Evaluating yolov8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 6/6 [00:03<00:00,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Loaded] yolov8s:latest from /tmp/yolov8s_fbpi3czn/model.onnx\n",
      "Ultralytics 8.3.182 🚀 Python-3.8.10 torch-2.3.1+cu121 CUDA:0 (NVIDIA A10G, 22724MiB)\n",
      "Loading /tmp/yolov8s_fbpi3czn/model.onnx for ONNX Runtime inference...\n",
      "Using ONNX Runtime CUDAExecutionProvider\n",
      "Setting batch=1 input of shape (1, 3, 640, 640)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 116.5±50.1 MB/s, size: 168.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/data/reference-cv-model-comparison/coco/labels/val2017.cache... 50 images, 2 backgrounds, 0 corrupt: 100%|██████████| 50/50 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 50/50 [00:00<00:00, 58.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         50        564       0.64       0.61      0.653      0.498\n",
      "Speed: 0.6ms preprocess, 6.4ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Results saved to \u001b[1m/tmp/ultra_runs/val_yolov8s:latest_subset50_20250821_132608\u001b[0m\n",
      "Loading /tmp/yolov8s_fbpi3czn/model.onnx for ONNX Runtime inference...\n",
      "Using ONNX Runtime CUDAExecutionProvider\n"
     ]
    }
   ],
   "source": [
    "#I needed to increase the shared memory usage to 10GB\n",
    "domino_user_name = os.environ['DOMINO_USER_NAME']\n",
    "experiment_name=f\"cv-benchmark-{domino_user_name}\"\n",
    "base_folder=f\"{download_base_folder}/coco\"\n",
    "\n",
    "utilities.ensure_mlflow_experiment(experiment_name)\n",
    "\n",
    "model_names = [\"yolov8n\", \"yolov5n\", \"yolov8m\", \"yolov8s\"]\n",
    "base_path=f\"{download_base_folder}/coco\"\n",
    "imgsz=640\n",
    "device=\"0\"\n",
    "limit_images=50\n",
    "subset_seed=0\n",
    "\n",
    "with mlflow.start_run(run_name=f\"parent_benchmark_{limit_images}\") as parent:\n",
    "    parent_id = parent.info.run_id\n",
    "    mlflow.log_params({\n",
    "                        \"base_path\":base_path,\n",
    "                        \"imgsz\": imgsz, \"device\": device,\n",
    "                        \"limit_images\": limit_images, \"subset_seed\": subset_seed\n",
    "                    })\n",
    "    for model_name in model_names:    \n",
    "        print(f\"Evaluating {model_name}\")\n",
    "        evaluate_model(\n",
    "            base_path=base_path,\n",
    "            registry_model_name=model_name,\n",
    "            registry_model_version=\"latest\",\n",
    "            imgsz=imgsz,\n",
    "            device=device,\n",
    "            limit_images=limit_images,\n",
    "            subset_seed=subset_seed,\n",
    "            experiment_name=None,          # experiment already set\n",
    "            parent_run_id=parent_id,       # pass parent\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4edffa-0a41-4389-b471-ab31f0c9ae47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#metrics = evaluate_model(f\"{download_base_folder}/coco\",model_path,limit_images=50,experiment_name=experiment_name,device=\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b2b21b-49dc-4a81-8a9f-453e39e6a341",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
