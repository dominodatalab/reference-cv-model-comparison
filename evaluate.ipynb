{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7b9e24b-35e9-4ab6-af35-a7a1ca89c749",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Requirement already satisfied: torch==2.3.1+cu121 in /home/domino/.local/lib/python3.8/site-packages (2.3.1+cu121)\n",
      "Requirement already satisfied: torchvision==0.18.1+cu121 in /home/domino/.local/lib/python3.8/site-packages (0.18.1+cu121)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from torch==2.3.1+cu121) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/domino/.local/lib/python3.8/site-packages (from torch==2.3.1+cu121) (4.13.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from torch==2.3.1+cu121) (1.11.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (from torch==2.3.1+cu121) (2.6.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch==2.3.1+cu121) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.8/dist-packages (from torch==2.3.1+cu121) (2023.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/domino/.local/lib/python3.8/site-packages (from torch==2.3.1+cu121) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/domino/.local/lib/python3.8/site-packages (from torch==2.3.1+cu121) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/domino/.local/lib/python3.8/site-packages (from torch==2.3.1+cu121) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/domino/.local/lib/python3.8/site-packages (from torch==2.3.1+cu121) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/domino/.local/lib/python3.8/site-packages (from torch==2.3.1+cu121) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/domino/.local/lib/python3.8/site-packages (from torch==2.3.1+cu121) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/domino/.local/lib/python3.8/site-packages (from torch==2.3.1+cu121) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/domino/.local/lib/python3.8/site-packages (from torch==2.3.1+cu121) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/domino/.local/lib/python3.8/site-packages (from torch==2.3.1+cu121) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/domino/.local/lib/python3.8/site-packages (from torch==2.3.1+cu121) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/domino/.local/lib/python3.8/site-packages (from torch==2.3.1+cu121) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in /home/domino/.local/lib/python3.8/site-packages (from torch==2.3.1+cu121) (2.3.1)\n",
      "Requirement already satisfied: numpy in /home/domino/.local/lib/python3.8/site-packages (from torchvision==0.18.1+cu121) (1.24.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision==0.18.1+cu121) (9.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/domino/.local/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.1+cu121) (12.9.86)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch==2.3.1+cu121) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/dist-packages (from sympy->torch==2.3.1+cu121) (1.2.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==2.3.1+cu121 torchvision==0.18.1+cu121 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beb50405-cf71-47af-a7ce-1e0adf2a92df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: onnxruntime-gpu==1.18.0 in /home/domino/.local/lib/python3.8/site-packages (1.18.0)\n",
      "Requirement already satisfied: coloredlogs in /home/domino/.local/lib/python3.8/site-packages (from onnxruntime-gpu==1.18.0) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /home/domino/.local/lib/python3.8/site-packages (from onnxruntime-gpu==1.18.0) (25.2.10)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /home/domino/.local/lib/python3.8/site-packages (from onnxruntime-gpu==1.18.0) (1.24.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from onnxruntime-gpu==1.18.0) (22.0)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.8/dist-packages (from onnxruntime-gpu==1.18.0) (3.20.1)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from onnxruntime-gpu==1.18.0) (1.11.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/domino/.local/lib/python3.8/site-packages (from coloredlogs->onnxruntime-gpu==1.18.0) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/dist-packages (from sympy->onnxruntime-gpu==1.18.0) (1.2.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade onnxruntime-gpu==1.18.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4459ea2-2742-4cad-87c5-a9b9f5cfd684",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36964526-ba0c-4b48-8765-8edb146d3a61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'AzureExecutionProvider', 'CPUExecutionProvider']\n"
     ]
    }
   ],
   "source": [
    "import os, onnxruntime as ort\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # or unset it: os.environ.pop(\"CUDA_VISIBLE_DEVICES\", None)\n",
    "\n",
    "# Must be the GPU build:\n",
    "# pip install --upgrade onnxruntime-gpu==1.18.0   # pick version matching your CUDA 12.x stack\n",
    "\n",
    "prov = ort.get_available_providers()\n",
    "print(prov)\n",
    "assert \"CUDAExecutionProvider\" in prov, f\"ORT not GPU-enabled. Providers={prov}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20d38dd6-3f28-460c-b010-c38e13305fb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasets_dir = os.environ['DOMINO_DATASETS_DIR']\n",
    "project_ds_folder = os.environ['DOMINO_PROJECT_NAME'] \n",
    "\n",
    "download_base_folder=f\"{datasets_dir}/{project_ds_folder}\"\n",
    "models_folder = \"models\"\n",
    "yolo_model_name=\"yolov8n\"\n",
    "\n",
    "yolo_onnx_file_name=f\"{yolo_model_name}.onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4aae6ad0-baf5-4f36-afc9-d09248480575",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Adds: log entire Ultralytics run dir to MLflow, then delete it.\n",
    "# Writes the run under /tmp/ultra_runs/<name>, logs it, removes it.\n",
    "\n",
    "import os, time, yaml, math, random, json, shutil, statistics as stats\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, List\n",
    "from datetime import datetime\n",
    "import mlflow\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "\n",
    "try:\n",
    "    import mlflow\n",
    "    _HAS_MLFLOW = True\n",
    "except Exception:\n",
    "    _HAS_MLFLOW = False\n",
    "\n",
    "\n",
    "def _ensure_dir(p: Path) -> Path:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "    return p\n",
    "\n",
    "\n",
    "def _latency_benchmark(model: YOLO, image_paths: List[Path], imgsz: int, device: str) -> Dict[str, Any]:\n",
    "    if not image_paths:\n",
    "        return {\"p50_ms\": None, \"p90_ms\": None, \"p99_ms\": None, \"mean_ms\": None, \"count\": 0}\n",
    "    lat_ms = []\n",
    "    _ = model.predict(source=str(image_paths[0]), imgsz=imgsz, device=device, verbose=False)  # warmup\n",
    "    for p in image_paths:\n",
    "        t0 = time.perf_counter()\n",
    "        _ = model.predict(source=str(p), imgsz=imgsz, device=device, verbose=False)\n",
    "        lat_ms.append((time.perf_counter() - t0) * 1000.0)\n",
    "    lat_sorted = sorted(lat_ms)\n",
    "    def pct(v, q):\n",
    "        idx = min(len(v)-1, max(0, int(math.ceil(q*len(v))-1)))\n",
    "        return v[idx]\n",
    "    return {\n",
    "        \"p50_ms\": pct(lat_sorted, 0.50),\n",
    "        \"p90_ms\": pct(lat_sorted, 0.90),\n",
    "        \"p99_ms\": pct(lat_sorted, 0.99),\n",
    "        \"mean_ms\": float(stats.mean(lat_sorted)),\n",
    "        \"count\": len(lat_sorted),\n",
    "        \"raw_ms\": lat_ms,\n",
    "    }\n",
    "\n",
    "\n",
    "def ensure_mlflow_experiment(experiment_name: str) -> int:\n",
    "    \"\"\"\n",
    "    Ensure an MLflow experiment with the given name exists.\n",
    "    If it does not, create it. Then set it as the current experiment.\n",
    "\n",
    "    Args:\n",
    "        experiment_name: Name of the experiment\n",
    "        artifact_location: Optional path or URI where artifacts will be stored\n",
    "\n",
    "    Returns:\n",
    "        experiment_id (int)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        exp = mlflow.get_experiment_by_name(experiment_name)\n",
    "        if exp is None:\n",
    "            exp_id = mlflow.create_experiment(\n",
    "                experiment_name\n",
    "            )\n",
    "        else:\n",
    "            exp_id = exp.experiment_id\n",
    "        mlflow.set_experiment(experiment_name)\n",
    "        return exp_id\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to ensure experiment {experiment_name}: {e}\")\n",
    "\n",
    "\n",
    "def evaluate_model(\n",
    "    base_path: str,\n",
    "    model_path: str,\n",
    "    imgsz: int = 640,\n",
    "    device: str = \"cpu\",\n",
    "    limit_images: int = 1000,\n",
    "    subset_seed: int = 0,\n",
    "    experiment_name:str = None\n",
    ") -> Dict[str, Any]:\n",
    "    base = Path(base_path)\n",
    "    img_dir = base / \"images\" / \"val2017\"\n",
    "    if not img_dir.exists():\n",
    "        raise FileNotFoundError(f\"Missing image dir: {img_dir}\")\n",
    "\n",
    "    artifacts = _ensure_dir(base / \"artifacts\")\n",
    "    plots_dir = _ensure_dir(artifacts / \"plots\")\n",
    "    metrics_dir = _ensure_dir(artifacts / \"metrics\")\n",
    "    config_dir = _ensure_dir(artifacts / \"config\")\n",
    "\n",
    "    all_imgs = sorted([p for p in img_dir.glob(\"*.jpg\")] +\n",
    "                      [p for p in img_dir.glob(\"*.jpeg\")] +\n",
    "                      [p for p in img_dir.glob(\"*.png\")])\n",
    "    if not all_imgs:\n",
    "        raise RuntimeError(f\"No images found under {img_dir}\")\n",
    "    rng = random.Random(subset_seed)\n",
    "    rng.shuffle(all_imgs)\n",
    "    sub_imgs = all_imgs[:min(limit_images, len(all_imgs))]\n",
    "\n",
    "    subset_list = artifacts / \"val_subset.txt\"\n",
    "    with open(subset_list, \"w\") as f:\n",
    "        for p in sub_imgs:\n",
    "            f.write(str(p.resolve()) + \"\\n\")\n",
    "\n",
    "    data_config = {\n",
    "        'path': str(base),\n",
    "        'train': 'images/val2017',\n",
    "        'val': str(subset_list),\n",
    "        'names': list(range(80))\n",
    "    }\n",
    "    yaml_path = base / \"coco_val_subset.yaml\"\n",
    "    with open(yaml_path, \"w\") as f:\n",
    "        yaml.dump(data_config, f)\n",
    "\n",
    "    model = YOLO(model_path, task=\"detect\")\n",
    "\n",
    "    # Force Ultralytics run dir into /tmp, give it a stable name\n",
    "    tmp_project = Path(\"/tmp/ultra_runs\")\n",
    "    run_name = f\"val_{Path(model_path).stem}_subset{len(sub_imgs)}_\" \\\n",
    "           f\"{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    val_res = model.val(\n",
    "        data=str(yaml_path),\n",
    "        imgsz=imgsz,\n",
    "        device=device,\n",
    "        save_json=False,\n",
    "        verbose=False,\n",
    "        project=str(tmp_project),   # <- /tmp base\n",
    "        name=run_name,              # <- folder name\n",
    "        exist_ok=True               # <- donâ€™t auto-increment\n",
    "        \n",
    "    )\n",
    "    save_dir = Path(val_res.save_dir)  # /tmp/ultra_runs/<run_name>\n",
    "\n",
    "    metrics = {\n",
    "        \"map\": float(val_res.box.map),\n",
    "        \"ap50\": float(val_res.box.map50),\n",
    "        \"ap75\": float(val_res.box.map75),\n",
    "        \"mean_precision\": float(val_res.box.mp),\n",
    "        \"mean_recall\": float(val_res.box.mr),\n",
    "        \"evaluated_images\": len(sub_imgs)\n",
    "    }\n",
    "    (metrics_dir / \"headline.json\").write_text(json.dumps(metrics, indent=2))\n",
    "\n",
    "    latency = _latency_benchmark(model, sub_imgs[:min(100, len(sub_imgs))], imgsz=imgsz, device=device)\n",
    "    (metrics_dir / \"latency.json\").write_text(json.dumps({k: v for k, v in latency.items() if k != \"raw_ms\"}, indent=2))\n",
    "\n",
    "    if latency.get(\"raw_ms\"):\n",
    "        plt.figure()\n",
    "        plt.hist(latency[\"raw_ms\"], bins=20)\n",
    "        plt.xlabel(\"Latency (ms)\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.title(\"Per-image latency (batch=1)\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(plots_dir / \"latency_hist.png\")\n",
    "        plt.close()\n",
    "\n",
    "    eval_cfg = {\n",
    "        \"imgsz\": imgsz,\n",
    "        \"device\": device,\n",
    "        \"subset_seed\": subset_seed,\n",
    "        \"limit_images\": limit_images,\n",
    "        \"subset_list\": str(subset_list),\n",
    "        \"model_path\": str(model_path),\n",
    "        \"ultralytics_save_dir\": str(save_dir),\n",
    "    }\n",
    "    (config_dir / \"eval.json\").write_text(json.dumps(eval_cfg, indent=2))\n",
    "\n",
    "    if _HAS_MLFLOW:\n",
    "        if experiment_name:\n",
    "            ensure_mlflow_experiment(experiment_name)\n",
    "        try:\n",
    "            with mlflow.start_run(run_name=run_name):\n",
    "                mlflow.log_params({\n",
    "                    \"imgsz\": imgsz, \"device\": device,\n",
    "                    \"limit_images\": len(sub_imgs), \"subset_seed\": subset_seed\n",
    "                })\n",
    "                mlflow.log_metrics({\n",
    "                    \"map\": metrics[\"map\"], \"ap50\": metrics[\"ap50\"], \"ap75\": metrics[\"ap75\"],\n",
    "                    \"mean_precision\": metrics[\"mean_precision\"], \"mean_recall\": metrics[\"mean_recall\"],\n",
    "                    \"latency_p50_ms\": latency.get(\"p50_ms\") or 0.0,\n",
    "                    \"latency_p90_ms\": latency.get(\"p90_ms\") or 0.0,\n",
    "                    \"latency_p99_ms\": latency.get(\"p99_ms\") or 0.0,\n",
    "                    \"latency_mean_ms\": latency.get(\"mean_ms\") or 0.0,\n",
    "                })\n",
    "                # Log our structured artifacts\n",
    "                mlflow.log_artifact(str(metrics_dir / \"headline.json\"))\n",
    "                mlflow.log_artifact(str(metrics_dir / \"latency.json\"))\n",
    "                mlflow.log_artifact(str(config_dir / \"eval.json\"))\n",
    "                mlflow.log_artifact(str(artifacts / \"val_subset.txt\"))\n",
    "                if (plots_dir / \"latency_hist.png\").exists():\n",
    "                    mlflow.log_artifact(str(plots_dir / \"latency_hist.png\"))\n",
    "                # Log the full Ultralytics run directory (results.csv/png, confusion matrix, samples, etc.)\n",
    "                if save_dir.exists():\n",
    "                    mlflow.log_artifacts(str(save_dir), artifact_path=\"ultralytics_run\")\n",
    "        finally:\n",
    "            # Always clean up the /tmp run directory\n",
    "            if save_dir.exists():\n",
    "                shutil.rmtree(save_dir, ignore_errors=True)\n",
    "            # Optional: prune empty parent\n",
    "            parent = tmp_project\n",
    "            if parent.exists() and not any(parent.iterdir()):\n",
    "                shutil.rmtree(parent, ignore_errors=True)\n",
    "\n",
    "    else:\n",
    "        # If MLflow isnâ€™t available, still clean up /tmp run dir\n",
    "        if save_dir.exists():\n",
    "            shutil.rmtree(save_dir, ignore_errors=True)\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03455c5b-60c5-4afa-b281-ef37e790fed8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/data/reference-cv-model-comparison/models/yolov8n.onnx\n"
     ]
    }
   ],
   "source": [
    "model_path = f\"{download_base_folder}/{models_folder}/{yolo_onnx_file_name}\"\n",
    "print(model_path)\n",
    "base_folder=f\"{download_base_folder}/coco\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e4edffa-0a41-4389-b471-ab31f0c9ae47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.181 ðŸš€ Python-3.8.10 torch-2.3.1+cu121 CUDA:0 (NVIDIA A10G, 22724MiB)\n",
      "Loading /mnt/data/reference-cv-model-comparison/models/yolov8n.onnx for ONNX Runtime inference...\n",
      "Using ONNX Runtime CUDAExecutionProvider\n",
      "Setting batch=1 input of shape (1, 3, 640, 640)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.7Â±0.1 ms, read: 110.5Â±49.7 MB/s, size: 168.9 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/data/reference-cv-model-comparison/coco/labels/val2017... 50 images, 2 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:00<00:00, 665.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /mnt/data/reference-cv-model-comparison/coco/labels/val2017.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:00<00:00, 87.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         50        564      0.528       0.53      0.585      0.446\n",
      "Speed: 0.6ms preprocess, 4.5ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Results saved to \u001b[1m/tmp/ultra_runs/val_yolov8n_subset50_20250820_142810\u001b[0m\n",
      "Loading /mnt/data/reference-cv-model-comparison/models/yolov8n.onnx for ONNX Runtime inference...\n",
      "Using ONNX Runtime CUDAExecutionProvider\n",
      "Ultralytics 8.3.181 ðŸš€ Python-3.8.10 torch-2.3.1+cu121 CPU (AMD EPYC 7R32)\n",
      "Loading /mnt/data/reference-cv-model-comparison/models/yolov8n.onnx for ONNX Runtime inference...\n",
      "Using ONNX Runtime CPUExecutionProvider\n",
      "Setting batch=1 input of shape (1, 3, 640, 640)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 101.4Â±41.7 MB/s, size: 150.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/data/reference-cv-model-comparison/coco/labels/val2017.cache... 50 images, 2 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:21<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         50        564      0.528      0.531      0.585      0.446\n",
      "Speed: 5.2ms preprocess, 240.5ms inference, 0.0ms loss, 132.4ms postprocess per image\n",
      "Results saved to \u001b[1m/tmp/ultra_runs/val_yolov8n_subset50_20250820_142821\u001b[0m\n",
      "Loading /mnt/data/reference-cv-model-comparison/models/yolov8n.onnx for ONNX Runtime inference...\n",
      "Using ONNX Runtime CPUExecutionProvider\n"
     ]
    }
   ],
   "source": [
    "domino_user_name = os.environ['DOMINO_USER_NAME']\n",
    "experiment_name=f\"cv-comparison-{domino_user_name}\"\n",
    "metrics = evaluate_model(f\"{download_base_folder}/coco\",model_path,limit_images=50,experiment_name=experiment_name,device=\"0\")\n",
    "metrics = evaluate_model(f\"{download_base_folder}/coco\",model_path,limit_images=50,experiment_name=experiment_name,device=\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fd6862-137b-4a0e-ab99-ca31adfd9b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
