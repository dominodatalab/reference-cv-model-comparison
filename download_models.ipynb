{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae3b4163-ea34-4bcc-90af-a7e60f7b9729",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8763831b-4e78-4b35-8bd2-014c476daad9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e371e59a-5f6b-422c-bdc4-8cfa09b9ee65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasets_dir = os.environ['DOMINO_DATASETS_DIR']\n",
    "project_ds_folder = os.environ['DOMINO_PROJECT_NAME'] \n",
    "\n",
    "download_base_folder=f\"{datasets_dir}/{project_ds_folder}\"\n",
    "models_folder = \"models\"\n",
    "yolo_model_name=\"yolov8n\"\n",
    "\n",
    "yolo_onnx_file_name=f\"{yolo_model_name}.onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ead45f5a-01fe-4593-a359-f7955b4692b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import onnx\n",
    "import mlflow\n",
    "import mlflow.onnx\n",
    "from ultralytics import YOLO\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.store.artifact.runs_artifact_repo import RunsArtifactRepository\n",
    "from mlflow.exceptions import MlflowException\n",
    "\n",
    "def download_and_register_yolov_models_with_client(\n",
    "    download_path: str,\n",
    "    models_folder: str,\n",
    "    experiment_name: str = \"YOLO_Export\"\n",
    "):\n",
    "\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    client = MlflowClient()\n",
    "\n",
    "    output_dir = os.path.join(download_path, models_folder)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Models to export -> register names (clean, no extension)\n",
    "    requests = [\n",
    "        (\"yolov8n.pt\", \"yolov8n\"),\n",
    "        (\"yolov5n.pt\", \"yolov5n\"),\n",
    "        (\"yolov8m.pt\", \"yolov8m\"),\n",
    "        (\"yolov8s.pt\", \"yolov8s\"),\n",
    "    ]\n",
    "\n",
    "    registered_versions = {}\n",
    "\n",
    "    for requested_name, registry_name in requests:\n",
    "        print(f\"[Export] {requested_name} -> ONNX\")\n",
    "        model = YOLO(requested_name)\n",
    "        onnx_src_path = model.export(format=\"onnx\")  # returns str path to .onnx\n",
    "\n",
    "        if not onnx_src_path or not os.path.isfile(onnx_src_path):\n",
    "            raise RuntimeError(f\"Export failed for {requested_name}\")\n",
    "\n",
    "        onnx_filename = os.path.basename(onnx_src_path)\n",
    "        final_path = os.path.join(output_dir, onnx_filename)\n",
    "        try:\n",
    "            shutil.move(onnx_src_path, final_path)\n",
    "        except OSError:\n",
    "            shutil.copy2(onnx_src_path, final_path)\n",
    "            os.remove(onnx_src_path)\n",
    "\n",
    "        if os.path.exists(requested_name):\n",
    "            os.remove(requested_name)\n",
    "\n",
    "        # Log ONNX with model flavor so the registry can version it\n",
    "        print(f\"[Log] {registry_name} to MLflow run\")\n",
    "        onnx_model = onnx.load(final_path)\n",
    "\n",
    "        with mlflow.start_run(run_name=f\"register_{registry_name}\") as run:\n",
    "            mlflow.onnx.log_model(onnx_model=onnx_model, artifact_path=\"model\")\n",
    "\n",
    "            # Build a runs:// URI then convert to the underlying store URI\n",
    "            runs_uri = f\"runs:/{run.info.run_id}/model\"\n",
    "            model_src = RunsArtifactRepository.get_underlying_uri(runs_uri)\n",
    "\n",
    "            # Ensure Registered Model exists\n",
    "            try:\n",
    "                client.create_registered_model(registry_name)\n",
    "            except MlflowException:\n",
    "                # Already exists or registry backend returns conflict; proceed to versioning\n",
    "                pass\n",
    "\n",
    "            # Create a Model Version pointing to this run‚Äôs logged model\n",
    "            print(f\"[Register] {registry_name} -> new version from run {run.info.run_id}\")\n",
    "            mv = client.create_model_version(\n",
    "                name=registry_name,\n",
    "                source=model_src,\n",
    "                run_id=run.info.run_id,\n",
    "                description=f\"Auto-registered {registry_name} ONNX export\",\n",
    "            )\n",
    "            registered_versions[registry_name] = mv.version\n",
    "\n",
    "    print(\"[Done] All models exported and registered.\")\n",
    "    return registered_versions\n",
    "\n",
    "\n",
    "def load_registered_yolo_model(model_name: str, version: str = \"latest\"):\n",
    "    \"\"\"\n",
    "    Downloads the registered ONNX model version and returns a Ultralytics YOLO instance.\n",
    "    \"\"\"\n",
    "    import mlflow\n",
    "    from ultralytics import YOLO\n",
    "\n",
    "    if version == \"latest\":\n",
    "        model_uri = f\"models:/{model_name}/latest\"\n",
    "    else:\n",
    "        model_uri = f\"models:/{model_name}/{version}\"\n",
    "\n",
    "    local_dir = mlflow.artifacts.download_artifacts(model_uri)\n",
    "    # look for single ONNX inside logged model dir\n",
    "    onnx_candidates = []\n",
    "    for root, _, files in os.walk(local_dir):\n",
    "        for f in files:\n",
    "            if f.endswith(\".onnx\"):\n",
    "                onnx_candidates.append(os.path.join(root, f))\n",
    "    if not onnx_candidates:\n",
    "        raise FileNotFoundError(f\"No .onnx found under {local_dir}\")\n",
    "\n",
    "    onnx_path = onnx_candidates[0]\n",
    "    return YOLO(onnx_path, task=\"detect\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "387e8a78-7f5b-4ccd-9961-1164de745a62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Export] yolov8n.pt -> ONNX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.25M/6.25M [00:00<00:00, 95.2MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.182 üöÄ Python-3.8.10 torch-2.3.1+cu121 CPU (AMD EPYC 7R32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv8n summary (fused): 72 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolov8n.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (6.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.12.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.64...\n",
      "WARNING ‚ö†Ô∏è \u001b[34m\u001b[1mONNX:\u001b[0m simplifier failure: module 'onnx.helper' has no attribute 'get_all_tensor_dtypes'\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 1.6s, saved as 'yolov8n.onnx' (12.2 MB)\n",
      "\n",
      "Export complete (2.7s)\n",
      "Results saved to \u001b[1m/mnt/code\u001b[0m\n",
      "Predict:         yolo predict task=detect model=yolov8n.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=yolov8n.onnx imgsz=640 data=coco.yaml  \n",
      "Visualize:       https://netron.app\n",
      "[Log] yolov8n to MLflow run\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/20 19:04:53 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: yolov8n, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Register] yolov8n -> new version from run f0d53b236821412e9a26884ca83c8e88\n",
      "[Export] yolov5n.pt -> ONNX\n",
      "PRO TIP üí° Replace 'model=yolov5n.pt' with new 'model=yolov5nu.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "\n",
      "Ultralytics 8.3.182 üöÄ Python-3.8.10 torch-2.3.1+cu121 CPU (AMD EPYC 7R32)\n",
      "YOLOv5n summary (fused): 84 layers, 2,649,200 parameters, 0 gradients, 7.7 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolov5nu.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (5.3 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.12.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.64...\n",
      "WARNING ‚ö†Ô∏è \u001b[34m\u001b[1mONNX:\u001b[0m simplifier failure: module 'onnx.helper' has no attribute 'get_all_tensor_dtypes'\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 1.2s, saved as 'yolov5nu.onnx' (10.3 MB)\n",
      "\n",
      "Export complete (2.1s)\n",
      "Results saved to \u001b[1m/mnt/code\u001b[0m\n",
      "Predict:         yolo predict task=detect model=yolov5nu.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=yolov5nu.onnx imgsz=640 data=coco.yaml  \n",
      "Visualize:       https://netron.app\n",
      "[Log] yolov5n to MLflow run\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/20 19:05:01 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: yolov5n, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Register] yolov5n -> new version from run df3b686c574e434b8dfd1370d7591508\n",
      "[Export] yolov8m.pt -> ONNX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8m.pt to 'yolov8m.pt': 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 49.7M/49.7M [00:00<00:00, 120MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.182 üöÄ Python-3.8.10 torch-2.3.1+cu121 CPU (AMD EPYC 7R32)\n",
      "YOLOv8m summary (fused): 92 layers, 25,886,080 parameters, 0 gradients, 78.9 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolov8m.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (49.7 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.12.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.64...\n",
      "WARNING ‚ö†Ô∏è \u001b[34m\u001b[1mONNX:\u001b[0m simplifier failure: module 'onnx.helper' has no attribute 'get_all_tensor_dtypes'\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 3.1s, saved as 'yolov8m.onnx' (99.0 MB)\n",
      "\n",
      "Export complete (8.3s)\n",
      "Results saved to \u001b[1m/mnt/code\u001b[0m\n",
      "Predict:         yolo predict task=detect model=yolov8m.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=yolov8m.onnx imgsz=640 data=coco.yaml  \n",
      "Visualize:       https://netron.app\n",
      "[Log] yolov8m to MLflow run\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/20 19:05:19 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: yolov8m, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Register] yolov8m -> new version from run f42babb5bd2a493db0a23e053b8faf24\n",
      "[Export] yolov8s.pt -> ONNX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt to 'yolov8s.pt': 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 21.5M/21.5M [00:00<00:00, 123MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.182 üöÄ Python-3.8.10 torch-2.3.1+cu121 CPU (AMD EPYC 7R32)\n",
      "YOLOv8s summary (fused): 72 layers, 11,156,544 parameters, 0 gradients, 28.6 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolov8s.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (21.5 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.12.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.64...\n",
      "WARNING ‚ö†Ô∏è \u001b[34m\u001b[1mONNX:\u001b[0m simplifier failure: module 'onnx.helper' has no attribute 'get_all_tensor_dtypes'\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 1.7s, saved as 'yolov8s.onnx' (42.8 MB)\n",
      "\n",
      "Export complete (3.6s)\n",
      "Results saved to \u001b[1m/mnt/code\u001b[0m\n",
      "Predict:         yolo predict task=detect model=yolov8s.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=yolov8s.onnx imgsz=640 data=coco.yaml  \n",
      "Visualize:       https://netron.app\n",
      "[Log] yolov8s to MLflow run\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/20 19:05:29 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: yolov8s, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Register] yolov8s -> new version from run fa8e5bedab3d4a9d84fae0059a8cdb4f\n",
      "[Done] All models exported and registered.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'yolov8n': '1', 'yolov5n': '1', 'yolov8m': '1', 'yolov8s': '1'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utilities.ensure_mlflow_experiment(utilities.model_registration_experiment_name)\n",
    "download_and_register_yolov_models_with_client(download_base_folder,models_folder,utilities.model_registration_experiment_name)\n",
    "#download_faster_rcnn(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b292db-22cc-40b8-bed6-af4f8f0e8b86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2191c175-c248-4f9d-8161-53d68bdb72db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, urllib.request, zipfile, shutil\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "def download_coco_2017_val_ds(base_dir):\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "    img_set = \"val2017\"\n",
    "    images_url = f\"http://images.cocodataset.org/zips/{img_set}.zip\"\n",
    "    ann_url    = \"http://images.cocodataset.org/annotations/annotations_trainval2017.zip\"\n",
    "\n",
    "    images_zip = os.path.join(base_dir, f\"{img_set}.zip\")\n",
    "    ann_zip    = os.path.join(base_dir, \"annotations_trainval2017.zip\")\n",
    "\n",
    "    # download\n",
    "    if not os.path.exists(images_zip):\n",
    "        print(f\"Downloading {os.path.basename(images_zip)}...\")\n",
    "        urllib.request.urlretrieve(images_url, images_zip)\n",
    "\n",
    "    if not os.path.exists(ann_zip):\n",
    "        print(f\"Downloading {os.path.basename(ann_zip)}...\")\n",
    "        urllib.request.urlretrieve(ann_url, ann_zip)\n",
    "\n",
    "    # extract images\n",
    "    target_images_dir = os.path.join(base_dir, \"images\", img_set)\n",
    "    if not os.path.exists(target_images_dir):\n",
    "        print(f\"Extracting {os.path.basename(images_zip)}...\")\n",
    "        with zipfile.ZipFile(images_zip, \"r\") as zf:\n",
    "            zf.extractall(base_dir)  # creates base_dir/val2017\n",
    "        os.makedirs(os.path.join(base_dir, \"images\"), exist_ok=True)\n",
    "        src = os.path.join(base_dir, img_set)  # base_dir/val2017\n",
    "        if os.path.exists(src):\n",
    "            shutil.move(src, target_images_dir)\n",
    "        else:\n",
    "            # already extracted to correct place by prior run\n",
    "            os.makedirs(target_images_dir, exist_ok=True)\n",
    "\n",
    "    # extract annotations\n",
    "    ann_dir = os.path.join(base_dir, \"annotations\")\n",
    "    ann_json = os.path.join(ann_dir, f\"instances_{img_set}.json\")\n",
    "    if not os.path.exists(ann_json):\n",
    "        print(f\"Extracting {os.path.basename(ann_zip)}...\")\n",
    "        with zipfile.ZipFile(ann_zip, \"r\") as zf:\n",
    "            zf.extractall(base_dir)  # creates base_dir/annotations/*.json\n",
    "    assert os.path.exists(ann_json), f\"Missing {ann_json}\"\n",
    "\n",
    "    # build labels\n",
    "    labels_dir = os.path.join(base_dir, \"labels\", img_set)\n",
    "    if not os.path.exists(labels_dir):\n",
    "        print(f\"Converting COCO ‚Üí YOLO labels into {labels_dir} ...\")\n",
    "        os.makedirs(labels_dir, exist_ok=True)\n",
    "\n",
    "        coco = COCO(ann_json)\n",
    "        cats = coco.loadCats(coco.getCatIds())\n",
    "        # COCO category ids are not 0..79; map to contiguous 0-based\n",
    "        catid2cls = {c[\"id\"]: i for i, c in enumerate(cats)}\n",
    "\n",
    "        img_ids = coco.getImgIds()\n",
    "        for img in coco.loadImgs(img_ids):\n",
    "            w, h = img[\"width\"], img[\"height\"]\n",
    "            ann_ids = coco.getAnnIds(imgIds=img[\"id\"], iscrowd=False)\n",
    "            anns = coco.loadAnns(ann_ids)\n",
    "\n",
    "            lines = []\n",
    "            for a in anns:\n",
    "                x, y, bw, bh = a[\"bbox\"]\n",
    "                if bw <= 0 or bh <= 0:\n",
    "                    continue\n",
    "                x_c = (x + bw / 2) / w\n",
    "                y_c = (y + bh / 2) / h\n",
    "                bw_n = bw / w\n",
    "                bh_n = bh / h\n",
    "                cls = catid2cls[a[\"category_id\"]]\n",
    "                lines.append(f\"{cls} {x_c:.6f} {y_c:.6f} {bw_n:.6f} {bh_n:.6f}\")\n",
    "\n",
    "            label_path = os.path.join(labels_dir, os.path.splitext(img[\"file_name\"])[0] + \".txt\")\n",
    "            with open(label_path, \"w\") as f:\n",
    "                f.write(\"\\n\".join(lines))\n",
    "\n",
    "    print(\"COCO 2017 val images, annotations, and YOLO labels are ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8bcee5-4cd5-4a4f-9de3-d54ddcfd58b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_coco_dir = f\"{download_base_folder}/coco\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7803e3c6-7028-48de-95cc-0bbb83293b23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prepare_coco_yolo(base_coco_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478ad419-9553-49af-a13d-9169f33fefce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
